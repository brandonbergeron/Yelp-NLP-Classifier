{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5: Group Project\n",
    "#### Author: Adam Pardo, Brandon Bergeron, Eric Bayless, Ramesh Babu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 - ML modeling  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--formatted printing for model scores\n",
    "\n",
    "def print_scores(model):\n",
    "    print(f'train score: {model.score(x_train, y_train)}')\n",
    "    print(f'test score: {model.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in reviews and combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combines all reviews for each restaurant into one observation\n",
    "\n",
    "#-read in reviews\n",
    "\n",
    "df_reviews = pd.read_csv('../data/Las_Vegas_reviews.csv') #-- All reviews\n",
    "#df_reviews = pd.read_csv('../data/Las_Vegas_400_reviews.csv') #-- Initial Sample\n",
    "\n",
    "\n",
    "#--combine all reviews\n",
    "df_revs_combined = df_reviews.groupby(['business_id', 'name', \n",
    "                               'address', 'city' ,\n",
    "                               'state', 'postal_code', \n",
    "                               'latitude' ,'longitude' , \n",
    "                               'stars', 'review_count', \n",
    "                               'is_open', 'attributes', 'categories']).agg({'text': ' '.join})\n",
    "\n",
    "#--reset index and add review length column for total \n",
    "df_revs_combined = df_revs_combined.reset_index()\n",
    "df_revs_combined['review_wc'] = df_revs_combined['text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "      <th>review_wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0RkJ_uIduNLWQrphbADRw</td>\n",
       "      <td>Rooster Boy Cafe</td>\n",
       "      <td>2620 Regatta Dr, Ste 113</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>89128</td>\n",
       "      <td>36.207539</td>\n",
       "      <td>-115.268154</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WheelchairAccessible': 'True', 'RestaurantsP...</td>\n",
       "      <td>Coffee &amp; Tea, Restaurants, Cafes, Food, Breakf...</td>\n",
       "      <td>Amazing food and service. So grateful for the ...</td>\n",
       "      <td>24200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id              name                   address  \\\n",
       "0  -0RkJ_uIduNLWQrphbADRw  Rooster Boy Cafe  2620 Regatta Dr, Ste 113   \n",
       "\n",
       "        city state  postal_code   latitude   longitude  stars  review_count  \\\n",
       "0  Las Vegas    NV        89128  36.207539 -115.268154    4.0           194   \n",
       "\n",
       "   is_open                                         attributes  \\\n",
       "0        1  {'WheelchairAccessible': 'True', 'RestaurantsP...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Coffee & Tea, Restaurants, Cafes, Food, Breakf...   \n",
       "\n",
       "                                                text  review_wc  \n",
       "0  Amazing food and service. So grateful for the ...      24200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_revs_combined.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: 72% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.724548\n",
       "0    0.275452\n",
       "Name: is_open, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_revs_combined['is_open'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- TTS, stratifying for imbalanced y\n",
    "\n",
    "x = df_revs_combined['text']\n",
    "y = df_revs_combined['is_open']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=251)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Preprocessors used in all models\n",
    "cvect = CountVectorizer(stop_words='english', max_features=1000)\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "ss = StandardScaler(with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.0\n",
      "test score: 0.7895927601809954\n"
     ]
    }
   ],
   "source": [
    "#-- Basic Logistic Regression to guage performance and get some feature imports for EDA\n",
    "\n",
    "logr = LogisticRegression(n_jobs=-1, max_iter=1000)\n",
    "\n",
    "pipe_logr = make_pipeline(cvect, ss, logr)\n",
    "pipe_logr.fit(x_train, y_train)\n",
    "\n",
    "print_scores(pipe_logr)\n",
    "\n",
    "#-- Extracting features and imports\n",
    "features = pipe_logr.named_steps.countvectorizer.get_feature_names()\n",
    "coefs = pipe_logr.named_steps.logisticregression.coef_\n",
    "coefs_df = pd.DataFrame({'importance': coefs[0]}, index = features)\n",
    "\n",
    "neg_imports = coefs_df.sort_values('importance', ascending=False).tail(50)\n",
    "pos_imports = coefs_df.sort_values('importance', ascending=False).head(50)\n",
    "\n",
    "#-- Combine imports into one df\n",
    "pos_neg_imports = pd.concat([pos_imports, neg_imports])\n",
    "\n",
    "#with open('pos_neg_imports.data', 'wb') as fh:\n",
    "    #pickle.dump(pos_neg_imports, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- instantiate basic versions of models to loop over\n",
    "\n",
    "model_dict = {\n",
    "    'LogisticRegression' : LogisticRegression(max_iter=1000, n_jobs=-1),\n",
    "    'MultinomialNB' : MultinomialNB(),\n",
    "    'RandomForest' : RandomForestClassifier(n_jobs=-1),\n",
    "    'ExtraTrees' : ExtraTreesClassifier(n_jobs=-1),\n",
    "    'K-NearestNeighbors' : KNeighborsClassifier(n_jobs=-1),\n",
    "    'SVC' : SVC(),\n",
    "    'AdaBoostClassifier' : AdaBoostClassifier(n_estimators=100),\n",
    "    'GradientBoostingClassifier' : GradientBoostingClassifier()    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Loop over base models with both vectorizers and get train/test scores for each\n",
    "\n",
    "df_models = {}\n",
    "\n",
    "for key in model_dict.keys():  \n",
    "    \n",
    "    estimator = model_dict[key]\n",
    "    \n",
    "    #-- pipelines for both vectorizers\n",
    "    pipe_cvect = make_pipeline(cvect, ss, estimator)\n",
    "    pipe_tfidf = make_pipeline(tfidf, ss, estimator)\n",
    "\n",
    "    #-- fit both \n",
    "    pipe_cvect.fit(x_train, y_train)\n",
    "    pipe_tfidf.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "    #-- gets scores and adds to df_models\n",
    "    \n",
    "    df_models[f'{key}_1'] = {\n",
    "        'preprocessing' : 'CountVectorizer',\n",
    "        'train_score' : pipe_cvect.score(x_train, y_train),\n",
    "        'test_score' : pipe_cvect.score(x_test, y_test)\n",
    "    }\n",
    "    \n",
    "    df_models[f'{key}_2'] = {\n",
    "        'preprocessing' : 'TfidfVectorizer',\n",
    "        'train_score' : pipe_tfidf.score(x_train, y_train),\n",
    "        'test_score' : pipe_tfidf.score(x_test, y_test)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    #--Printing for progress\n",
    "    #print(f'{key} with CountVectorizer:')\n",
    "    #print_scores(pipe_cvect)\n",
    "    #print()\n",
    "    #print(f'{key} with TfidfVectorizer:')\n",
    "    #print_scores(pipe_tfidf)\n",
    "    #print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_models = pd.DataFrame(df_models).T\n",
    "#df_first_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Baseline improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>K-NearestNeighbors</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model    Preprocessing  Accuracy  Baseline improvement\n",
       "1  GradientBoostingClassifier  TfidfVectorizer     0.830                 0.105\n",
       "2          AdaBoostClassifier  TfidfVectorizer     0.799                 0.074\n",
       "3                         SVC  TfidfVectorizer     0.796                 0.071\n",
       "4          LogisticRegression  CountVectorizer     0.781                 0.056\n",
       "5          LogisticRegression  TfidfVectorizer     0.774                 0.049\n",
       "6                RandomForest  TfidfVectorizer     0.765                 0.040\n",
       "7                  ExtraTrees  TfidfVectorizer     0.758                 0.033\n",
       "8          K-NearestNeighbors  TfidfVectorizer     0.742                 0.017"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- Cleaning for presentation\n",
    "\n",
    "df_first_models.sort_values('test_score', ascending=False, inplace=True)\n",
    "df_first_models['train_score'] = df_first_models['train_score'].astype(float)\n",
    "df_first_models['test_score'] = df_first_models['test_score'].astype(float)\n",
    "df_first_models = df_first_models.round(decimals=3).head(8)\n",
    "df_first_models\n",
    "df_first_models['model'] = df_first_models.index\n",
    "df_first_models.reset_index(inplace=True, drop=True)\n",
    "df_first_models = df_first_models[['model', 'preprocessing', 'test_score']]\n",
    "df_first_models['model'] = [mod[:-2] for mod in df_first_models['model']]\n",
    "df_first_models.columns = ['Model', 'Preprocessing', 'Accuracy']\n",
    "df_first_models['Baseline improvement'] = df_first_models['Accuracy'] - .725\n",
    "df_first_models.index = df_first_models.index+1\n",
    "df_first_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/first_models.data', 'wb') as fh:\n",
    "#    pickle.dump(df_first_models, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Tokenizer and Parameter Searching with GridSearchCV\n",
    "\n",
    "Each model will be fit using the word vectorizer that perfomed best on initial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Tokenizer for \n",
    "\n",
    "def split_lemmatize(text):\n",
    "    'returns a lowercase lemmatized list of words'\n",
    "    text_lower = text.lower()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(x) for x in text_lower.split()])\n",
    "\n",
    "tfidf_lem = TfidfVectorizer(preprocessor = split_lemmatize, stop_words = 'english', max_features=1000)\n",
    "cvect_lem = CountVectorizer(preprocessor = split_lemmatize, stop_words = 'english', max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Preprocessing words for model speed\n",
    "\n",
    "x_train_tf = tfidf_lem.fit_transform(x_train)\n",
    "x_test_tf = tfidf_lem.transform(x_test)\n",
    "\n",
    "x_train_cv = cvect_lem.fit_transform(x_train)\n",
    "x_test_cv = cvect_lem.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with GridSearch\n",
      "train score: 1.0\n",
      "test score: 0.7692307692307693\n",
      "best params: {'logisticregression__C': 0, 'logisticregression__penalty': 'none'}\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "\n",
    "pipe_logreg = make_pipeline(ss, logreg)\n",
    "\n",
    "params = {\n",
    "    'logisticregression__C' : [0, 1, 10, 100],\n",
    "    'logisticregression__penalty' : ['l1', 'l2', 'elasticnet', 'none'],    \n",
    "}\n",
    "\n",
    "grid_logreg = GridSearchCV(pipe_logreg, params, n_jobs=-1)\n",
    "grid_logreg.fit(x_train_cv, y_train)\n",
    "\n",
    "\n",
    "print('Logistic Regression with GridSearch')\n",
    "print(f'train score: {grid_logreg.score(x_train_cv, y_train)}')\n",
    "print(f'test score: {grid_logreg.score(x_test_cv, y_test)}')\n",
    "print(f'best params: {grid_logreg.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with GridSearch:\n",
      "train score: 0.997737556561086\n",
      "test score: 0.7692307692307693\n",
      "best params: {'randomforestclassifier__max_depth': 20, 'randomforestclassifier__min_samples_leaf': 3, 'randomforestclassifier__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "pipe_forest = make_pipeline(ss, forest)\n",
    "\n",
    "params_forest = {\n",
    "    'randomforestclassifier__min_samples_leaf' : [3, 5, 10, 20],\n",
    "    'randomforestclassifier__n_estimators' : [100, 200, 300],\n",
    "    'randomforestclassifier__max_depth' : [5, 10, 20, None]\n",
    "}\n",
    "\n",
    "grid_forest = GridSearchCV(pipe_forest, params_forest, n_jobs=-1)\n",
    "\n",
    "grid_forest.fit(x_train_tf, y_train)\n",
    "\n",
    "\n",
    "print('RandomForest with GridSearch:')\n",
    "print(f'train score: {grid_forest.score(x_train_tf, y_train)}')\n",
    "print(f'test score: {grid_forest.score(x_test_tf, y_test)}')\n",
    "print(f'best params: {grid_forest.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with GridSearch:\n",
      "train score: 0.782051282051282\n",
      "test score: 0.7330316742081447\n",
      "best params: {'kneighborsclassifier__n_neighbors': 15, 'kneighborsclassifier__p': 1}\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "pipe_knn = make_pipeline(ss, knn)\n",
    "\n",
    "params_knn = {\n",
    "    'kneighborsclassifier__n_neighbors' : [3, 5, 7, 9, 15],\n",
    "    'kneighborsclassifier__p' : [1, 2]\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(pipe_knn, params_knn, n_jobs=-1)\n",
    "\n",
    "grid_knn.fit(x_train_cv, y_train)\n",
    "\n",
    "\n",
    "print('RandomForest with GridSearch:')\n",
    "print(f'train score: {grid_knn.score(x_train_cv, y_train)}')\n",
    "print(f'test score: {grid_knn.score(x_test_cv, y_test)}')\n",
    "print(f'best params: {grid_knn.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with GridSearch:\n",
      "train score: 1.0\n",
      "test score: 0.8212669683257918\n",
      "best params: {'svc__C': 5, 'svc__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "\n",
    "pipe_svc = make_pipeline(ss, svc)\n",
    "\n",
    "params_svc = {\n",
    "    'svc__kernel' : ['rbf', 'sigmoid'],\n",
    "    'svc__C' : [0, 1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_svc = GridSearchCV(pipe_svc, params_svc, n_jobs=-1)\n",
    "grid_svc.fit(x_train_tf, y_train)\n",
    "\n",
    "\n",
    "print('SVC with GridSearch:')\n",
    "print(f'train score: {grid_svc.score(x_train_tf, y_train)}')\n",
    "print(f'test score: {grid_svc.score(x_test_tf, y_test)}')\n",
    "print(f'best params: {grid_svc.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost with GridSearch\n",
      "train score: 1.0\n",
      "test score: 0.8009049773755657\n",
      "best_params: {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier()\n",
    "\n",
    "pipe_boost = make_pipeline(ss, adaboost)\n",
    "\n",
    "params_boost = {\n",
    "    'adaboostclassifier__n_estimators' : [50, 100, 200],\n",
    "    'adaboostclassifier__learning_rate' : [1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_boost = GridSearchCV(pipe_boost, params_boost, n_jobs=-1)\n",
    "grid_boost.fit(x_train_tf, y_train)\n",
    "\n",
    "print('AdaBoost with GridSearch')\n",
    "print(f'train score: {grid_boost.score(x_train_tf, y_train)}')\n",
    "print(f'test score: {grid_boost.score(x_test_tf, y_test)}')\n",
    "print(f'best_params: {grid_boost.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradBoost with GridSearch\n",
      "train score: 0.9969834087481146\n",
      "test score: 0.8461538461538461\n",
      "best_params: {'gradientboostingclassifier__ccp_alpha': 0, 'gradientboostingclassifier__max_depth': 3, 'gradientboostingclassifier__min_samples_leaf': 20}\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "\n",
    "pipe_gboost = make_pipeline(ss, gboost)\n",
    "\n",
    "params_gboost = {\n",
    "    'gradientboostingclassifier__min_samples_leaf' : [1, 3, 6, 10, 20],\n",
    "    'gradientboostingclassifier__max_depth' : [3, 5, 9],\n",
    "    'gradientboostingclassifier__ccp_alpha' : [0, 1, 10, 100]\n",
    "\n",
    "}\n",
    "\n",
    "grid_gboost = GridSearchCV(pipe_gboost, params_gboost, n_jobs=-1)\n",
    "grid_gboost.fit(x_train_tf, y_train)\n",
    "\n",
    "print('GradBoost with GridSearch')\n",
    "print(f'train score: {grid_gboost.score(x_train_tf, y_train)}')\n",
    "print(f'test score: {grid_gboost.score(x_test_tf, y_test)}')\n",
    "print(f'best_params: {grid_gboost.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing GridSearch Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Dictionary of all GridSearches for bilding DF of metrics\n",
    "\n",
    "grid_dict = {\n",
    "    'LogisticRegression' : {'preprocesser':'cv', 'model':grid_logreg},\n",
    "    'RandomForest' : {'preprocesser':'tf', 'model':grid_forest},\n",
    "    'KNN' : {'preprocesser':'cv', 'model':grid_knn},\n",
    "    'SVC' : {'preprocesser':'tf', 'model':grid_svc},\n",
    "    'AdaBoostClassifier' : {'preprocesser':'tf', 'model':grid_boost},\n",
    "    'GradientBoostingClassifier' : {'preprocesser':'tf', 'model':grid_gboost}\n",
    "}\n",
    "\n",
    "metrics_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Builds DF of metrics for all GridSearches\n",
    "\n",
    "for grid in grid_dict.keys():\n",
    "    if grid_dict[grid]['preprocesser'] == 'cv':\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, grid_dict[grid]['model'].predict(x_test_cv)).flatten()\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        balanced_acc = (specificity+recall)/2\n",
    "        metrics_dict[grid] = {\n",
    "            'precision' : precision,\n",
    "            'recall' : recall,\n",
    "            'specificity' : specificity,\n",
    "            'balanced accuracy' : balanced_acc,\n",
    "            'accuracy' : grid_dict[grid]['model'].score(x_test_cv, y_test)\n",
    "        }\n",
    "    else:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, grid_dict[grid]['model'].predict(x_test_tf)).flatten()\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        balanced_acc = (specificity+recall)/2\n",
    "        metrics_dict[grid] = {\n",
    "            'precision' : precision,\n",
    "            'recall' : recall,\n",
    "            'specificity' : specificity,\n",
    "            'balanced accuracy' : balanced_acc,\n",
    "            'accuracy' : grid_dict[grid]['model'].score(x_test_tf, y_test)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--DF of all metrics for best models\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics['improvement'] = df_metrics['accuracy'] - [.7805, .7647, .7421, .7964, .7986, .8303]\n",
    "#df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Model Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.769</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.733</td>\n",
       "      <td>-0.009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Recall  Specificity  Balanced Accuracy  \\\n",
       "1  GradientBoostingClassifier   0.959        0.549              0.754   \n",
       "2                         SVC   0.919        0.566              0.742   \n",
       "3          AdaBoostClassifier   0.891        0.566              0.728   \n",
       "4          LogisticRegression   0.825        0.623              0.724   \n",
       "5                RandomForest   0.984        0.205              0.595   \n",
       "6                         KNN   0.950        0.164              0.557   \n",
       "\n",
       "   Accuracy  Model Improvement  \n",
       "1     0.846              0.016  \n",
       "2     0.821              0.025  \n",
       "3     0.801              0.002  \n",
       "4     0.769             -0.011  \n",
       "5     0.769              0.005  \n",
       "6     0.733             -0.009  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--- Cleaning for presentation\n",
    "\n",
    "df_metrics = df_metrics.round(decimals=3).sort_values('accuracy', ascending=False).drop(['precision'], axis=1)\n",
    "df_metrics['model'] = df_metrics.index\n",
    "df_metrics.reset_index(inplace=True, drop=True)\n",
    "df_metrics.index += 1\n",
    "df_metrics = df_metrics[[ 'model', 'recall', 'specificity', 'balanced accuracy', 'accuracy', 'improvement']]\n",
    "df_metrics.columns = ['Model', 'Recall', 'Specificity', 'Balanced Accuracy', 'Accuracy', 'Model Improvement']\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/gridsearch_metrics.data', 'wb') as fh:\n",
    "#    pickle.dump(df_metrics, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
